# Sentiment analysis in Twitter for the Medellin Development Plan

*Project repository - 'Sentiment Analysis in Twitter for the Medellin Development Plan' by group 247 of the 6th cohort of DS4A Colombia.*


![Sentiment-Analysis-for-the-MDP](https://socialify.git.ci/GDLPLearning/Sentiment-Analysis-for-the-MDP/image?description=1&font=Raleway&forks=1&issues=1&language=1&name=1&owner=1&pattern=Plus&pulls=1&stargazers=1&theme=Light)
https://socialify.git.ci/
## Add shields io badges
Shields.io
## Project Description

What your application does,

Why you used the technologies you used,

Some of the challenges you faced and features you hope to implement in the future.

## Table of Contents 


## Project Demo

## Project Screenshots

## How to Install and Run the Project
Provide a step-by-step description of how to get the development environment set and running.

## How to Use the Project
You can also make use of visual aids by including materials like screenshots to show examples of the running project and also the structure and design principles used in your project.

Also if your project will require authentication like passwords or usernames, this is a good section to include the credentials.


## Technologies used

## Credits
If you worked on the project as a team or an organization, list your collaborators/team members. You should also include links to their GitHub profiles and social media too.

Also, if you followed tutorials or referenced a certain material that might help the user to build that particular project, include links to those here as well.


## License
https://choosealicense.com/


## Contribution Guidelines

https://docs.github.com/en/communities/setting-up-your-project-for-healthy-contributions/setting-guidelines-for-repository-contributors


## Tests


Project Organization
------------

    ├─ LICENSE
    ├── Makefile            <- Makefile with commands like `make data` or `make train`
    ├── README.md           <- The top-level README for developers using this project.
    ├── data
    │    ├── external       <- Data from third party sources. 
    │    ├── final          <- Data after training the model
    │    ├── interim        <- Intermediate data that has been transformed.
    │    ├── processed      <- The final, canonical data sets for modeling.
    │    └── raw            <- The original, immutable data dump.
    │
    ├── docs                <- A default Sphinx project; see sphinx-doc.org for details
    │
    ├── models              <- Trained and serialized models, model predictions, or model summaries
    │
    ├── notebooks           <- Jupyter notebooks. Naming convention is a number (for ordering),
    │    │                       the creator's initials, and a short `-` delimited description, e.g.
    │    │                       `1.0-jqp-initial-data-exploration`.
    │    │
    │    ├── exploratoy     <- Contains initial explorations
    │    └── reports        <- More polished work that can be exported as html to the reports directory.
    │
    ├── references          <- Data dictionaries, manuals, and all other explanatory materials.
    │
    ├── reports             <- Generated analysis as HTML, PDF, LaTeX, etc.
    │    └── figures        <- Generated graphics and figures to be used in reporting
    │
    ├── requirements.txt    <- The requirements file for reproducing the analysis environment, e.g.
    │                          generated with `pip freeze > requirements.txt`
    │
    ├── setup.py            <- Makes project pip installable (pip install -e .) so src can be imported
    ├── src                 <- Source code for use in this project.
    │   ├── __init__.py     <- Makes src a Python module
    │   │
    │   ├── data            <- Scripts to download or generate data
    │   │   └── make_dataset.py
    │   │
    │   ├── features        <- Scripts to turn raw data into features for modeling
    │   │   └── build_features.py
    │   │
    │   ├── models          <- Scripts to train models and then use trained models to make
    │   │   │                  predictions
    │   │   ├── predict_model.py
    │   │   └── train_model.py
    │   │
    │   └── visualization   <- Scripts to create exploratory and results oriented visualizations
    │       └── visualize.py
    ├── tests               <-  Store tests
    ├── __init__.py         <-  Make tests a Python module 
    ├── test_process.py     <-  Test functions for process.py
    ├── test_train_model.py <-  Test functions for train_model.py
    │
    └── tox.ini             <-  Tox file with settings for running tox; see tox.readthedocs.io


--------

<
