{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will structure this section as follows:\n",
    "1. [Collect data](#1-collect-data)\n",
    "2. [Describe data](#2-describe-data)\n",
    "3. [Explore data](#3-explore-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import json\n",
    "import credentials as cr\n",
    "\n",
    "#Add your credentials here\n",
    "twitter_keys = {\n",
    "  'consumer_key': cr.api_key,\n",
    "  'consumer_secret': cr.api_secret_key,\n",
    "  'access_token_key': cr.acces_token,\n",
    "  'access_token_secret': cr.acces_token_secret   \n",
    "}\n",
    "\n",
    "#Setup access to API\n",
    "auth = tw.OAuthHandler(twitter_keys['consumer_key'], twitter_keys['consumer_secret'])\n",
    "auth.set_access_token(twitter_keys['access_token_key'], twitter_keys['access_token_secret'])\n",
    "\n",
    "# setting the connection with the API\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_the_query(search_query):\n",
    "\n",
    "  '''\n",
    "  recieve one parameter, the key word that we will use to filter the request \n",
    "  and returns a list with all the fetched tweets \n",
    "  '''\n",
    "  query = search_query + ' medellin -filter:retweets' \n",
    "  date_since = \"2018-11-16\"  # date filter to search the tweets\n",
    "\n",
    "  tweets = tw.Cursor(api.search,\n",
    "                    q=query,\n",
    "                    lang=\"es\",\n",
    "                    since=date_since,\n",
    "                    tweet_mode=\"extended\").items(2)\n",
    "\n",
    "  list_of_tweets = [[tweet.full_text, \n",
    "                    tweet.user.screen_name, \n",
    "                    tweet.user.location,\n",
    "                    tweet.created_at,\n",
    "                    tweet.id,\n",
    "                    tweet.retweet_count,\n",
    "                    tweet.favorite_count] for tweet in tweets]\n",
    "  \n",
    "  return list_of_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_the_df(list_of_tweets):\n",
    "\n",
    "  '''\n",
    "  Recieve one parameter, the list with all the tweets and return a dataFrame\n",
    "  '''\n",
    "\n",
    "  # creating the dic to fill with the tweets that we fetch\n",
    "  diccionario = {\n",
    "      'texto':[],\n",
    "      'usuario':[],\n",
    "      'ubicacion':[],\n",
    "      'fecha':[],\n",
    "      'tweet_id':[],\n",
    "      'numero_rt':[],\n",
    "      'numero_likes':[]\n",
    "  }\n",
    "\n",
    "  count = 0\n",
    "  dict_to_fill = diccionario.copy()\n",
    "\n",
    "  for row in range(len(list_of_tweets)):\n",
    "    \n",
    "    # agregando los datos al diccionario\n",
    "    dict_to_fill['texto'].append(list_of_tweets[row][0])\n",
    "    dict_to_fill['usuario'].append(list_of_tweets[row][1])\n",
    "    dict_to_fill['ubicacion'].append(list_of_tweets[row][2])\n",
    "    dict_to_fill['fecha'].append(list_of_tweets[row][3])\n",
    "    dict_to_fill['tweet_id'].append(list_of_tweets[row][4])\n",
    "    dict_to_fill['numero_rt'].append(list_of_tweets[row][5])\n",
    "    dict_to_fill['numero_likes'].append(list_of_tweets[row][6])\n",
    "\n",
    "  df = pd.DataFrame.from_dict(dict_to_fill)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palabras claves seleccionadas para realizar la busqueda\n",
    "palabras_claves = [\n",
    "                   '\"movilidad sostenible\"', '\"movilidad inteligente\"', '\"servicios publicos\"',\n",
    "                   '\"energias alternativas\"', '\"reciclaje\"', '\"energias renovables\"',\n",
    "                   '\"urbanimo ecologico\"', '\"urbanismo\"', '\"desarrollo rural\"',\n",
    "                   '\"bienestar animal\"', '\"biodiversidad\"', '\"energias limpias\"',\n",
    "                   '\"movilidad\"','\"reciclar\"', '\"energias\"', '\"rural\"',\n",
    "]\n",
    "\n",
    "count = 0\n",
    "\n",
    "# creando una consulta para cada palabra clave\n",
    "for search_query in palabras_claves:\n",
    "\n",
    "  list_of_tweets = making_the_query(search_query)\n",
    "  df = create_the_df(list_of_tweets)\n",
    "  # creando una nueva columna con la palabra clave\n",
    "  df['palabra_clave'] = search_query.replace('\"','')\n",
    "\n",
    "  if count == 0:\n",
    "    df_final = df.copy()\n",
    "    count = 1\n",
    "  else:\n",
    "    df_final = df_final.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Describe data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
